client:
  engine: openai
  is_async: false
  mode: JSON_O1

generation:
  model: o4-mini-2025-04-16
  temperature: 1.0
  max_tokens: 4096

logging:
  out: logs/theorem_proving_o4mini.log
  level: info

start_idx: 0
end_idx: null

max_retries: 1
input_path: /path/to/formalization/input
output_path: /path/to/output